# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°
import datasets  # ğŸ¤– ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain.docstore.document import Document  # ğŸ“ ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain.text_splitter import RecursiveCharacterTextSplitter  # ğŸ“„ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.retrievers import BM25Retriever  # ğŸ” BM25 ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ ê²€ìƒ‰ê¸°(retriever)
from smolagents import Tool  # ğŸ› ï¸ ë„êµ¬(Tool) ìƒì„± ë° ê´€ë¦¬
from smolagents import HfApiModel, CodeAgent  # ğŸ¤– ì½”ë“œ ì—ì´ì „íŠ¸ì™€ Hugging Face API ëª¨ë¸
from smolagents import CodeAgent, LiteLLMModel  # ğŸ§  ê°€ë²¼ìš´ LLM ëª¨ë¸ê³¼ ì½”ë“œ ì—ì´ì „íŠ¸

# ğŸ’¾ Hugging Faceì˜ transformers ë¬¸ì„œ ë°ì´í„°ì…‹ì„ ë¡œë“œ
knowledge_base = datasets.load_dataset("m-ric/huggingface_doc", split="train")

# ğŸ” transformers ê´€ë ¨ ë¬¸ì„œë§Œ í•„í„°ë§
knowledge_base = knowledge_base.filter(lambda row: row["source"].startswith("huggingface/transformers"))

# ğŸ“„ ë¬¸ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì¶œì²˜ ì •ë³´ í¬í•¨)
source_docs = [
    Document(page_content=doc["text"], metadata={"source": doc["source"].split("/")[1]})
    for doc in knowledge_base
]

# ğŸ“š í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•˜ëŠ” ì„¤ì • (ë¬¸ì„œ ê²€ìƒ‰ì˜ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•¨)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # ğŸ“ í•œ ì¡°ê°ì˜ ìµœëŒ€ ê¸¸ì´ (500ì)
    chunk_overlap=50,  # ğŸ”„ ì¡°ê° ê°„ì˜ ê²¹ì¹˜ëŠ” ë¶€ë¶„ (50ì)
    add_start_index=True,  # ğŸ”¢ ì‹œì‘ ì¸ë±ìŠ¤ ì¶”ê°€
    strip_whitespace=True,  # ğŸš€ ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    separators=["\n\n", "\n", ".", " ", ""],  # ğŸ“ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•  ê¸°ì¤€
)

# ğŸ“œ ë¬¸ì„œë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°
docs_processed = text_splitter.split_documents(source_docs)


# ğŸ”§ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ ë„êµ¬(Tool) í´ë˜ìŠ¤
class RetrieverTool(Tool):
    name = "retriever"  # ğŸ·ï¸ ë„êµ¬ì˜ ì´ë¦„
    description = "transformers ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ëŠ” ê¸°ëŠ¥"  # ğŸ“œ ë„êµ¬ì˜ ì„¤ëª…
    inputs = {
        "query": {
            "type": "string",
            "description": "ê²€ìƒ‰í•  ë‚´ìš©. ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.",
        }
    }
    output_type = "string"  # ğŸ“„ ì¶œë ¥ í˜•ì‹ (ë¬¸ìì—´)

    def __init__(self, docs, **kwargs):
        super().__init__(**kwargs)
        self.retriever = BM25Retriever.from_documents(
            docs, k=10  # ğŸ” ìµœëŒ€ 10ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰
        )

    # ğŸ” ê²€ìƒ‰ ì‹¤í–‰
    def forward(self, query: str) -> str:
        assert isinstance(query, str), "ê²€ìƒ‰ì–´ëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤!"

        docs = self.retriever.invoke(query)  # ğŸ” ê²€ìƒ‰ ìˆ˜í–‰
        return "\nê²€ìƒ‰ëœ ë¬¸ì„œ:\n" + "".join(
            [
                f"\n\n===== ë¬¸ì„œ {str(i)} =====\n" + doc.page_content
                for i, doc in enumerate(docs)
            ]
        )


# ğŸ› ï¸ ê²€ìƒ‰ ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
retriever_tool = RetrieverTool(docs_processed)

# ğŸ¤– ì‚¬ìš©í•  LLM ëª¨ë¸ ì„¤ì •
model = LiteLLMModel(
    model_id="ollama_chat/llama3.2:3b",  # ğŸ¯ ì‚¬ìš©í•  ëª¨ë¸ (3B í¬ê¸°ì˜ Llama3.2)
    api_base="http://localhost:11434",  # ğŸŒ ë¡œì»¬ ì„œë²„ì—ì„œ API ì‹¤í–‰
    num_ctx=8192,  # ğŸ“ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ (ê¸°ë³¸ê°’ 2048ë³´ë‹¤ í¬ê²Œ ì„¤ì •í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€)
)

# ğŸ§  ì½”ë“œ ì‹¤í–‰ ì—ì´ì „íŠ¸(CodeAgent) ìƒì„±
agent = CodeAgent(
    tools=[retriever_tool],  # ğŸ› ï¸ ë„êµ¬ ì¶”ê°€ (ê²€ìƒ‰ ê¸°ëŠ¥ í¬í•¨)
    model=model,  # ğŸ¤– ëª¨ë¸ ì§€ì •
    add_base_tools=True,  # ğŸ”§ ê¸°ë³¸ ë„êµ¬ í¬í•¨ ì—¬ë¶€ (ì˜ˆ: ê³„ì‚°ê¸°, íŒŒì¼ ê´€ë¦¬ ë“±)
    additional_authorized_imports=['numpy', 'sys', 'wikipedia', 'requests', 'bs4']  # ğŸ“š í—ˆìš©ëœ ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬
)

# ğŸƒâ€â™‚ï¸ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ transformers ëª¨ë¸ í›ˆë ¨ ì†ë„ ê´€ë ¨ ì§ˆë¬¸ì„ ì²˜ë¦¬
agent_output = agent.run("íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ í›ˆë ¨í•  ë•Œ, ìˆœì „íŒŒ(forward)ì™€ ì—­ì „íŒŒ(backward) ì¤‘ ì–´ë–¤ ê²ƒì´ ë” ëŠë¦°ê°€ìš”?")

# ğŸ“¢ ìµœì¢… ê²°ê³¼ ì¶œë ¥
print("ìµœì¢… ì¶œë ¥:")
print(agent_output)